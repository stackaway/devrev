{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'The model bigscience/bloomz is too large to be loaded automatically (352GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "API_URL = 'https://api-inference.huggingface.co/models/bigscience/bloomz'\n",
    "# headers = {'Authorization': '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'}\n",
    "headers = {'Authorization': 'Bearer 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'}\n",
    "\n",
    "# The Entertheaccesskeyhere is just a placeholder, which can be changed according to the user's access key\n",
    "\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "  \n",
    "params = {'max_length': 2, 'top_k': 10, 'temperature': 2.5}\n",
    "output = query({\n",
    "    'inputs': 'Sherlock Holmes is a',\n",
    "    'parameters': params,\n",
    "})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'Suvojit', 'end': 18, 'score': 0.7182998657226562, 'start': 11},\n",
      " {'answer': 'Suvojit', 'end': 18, 'score': 0.004904397297650576, 'start': 11},\n",
      " {'answer': 'Suvojit and I am a Senior Data Scientist',\n",
      "  'end': 51,\n",
      "  'score': 0.004658981692045927,\n",
      "  'start': 11},\n",
      " {'answer': 'My name is Suvojit',\n",
      "  'end': 18,\n",
      "  'score': 0.0018861714052036405,\n",
      "  'start': 0},\n",
      " {'answer': 'name is Suvojit',\n",
      "  'end': 18,\n",
      "  'score': 0.00026283299666829407,\n",
      "  'start': 3},\n",
      " {'answer': 'Suvojit', 'end': 18, 'score': 0.00017349491827189922, 'start': 11},\n",
      " {'answer': 'Suvojit', 'end': 18, 'score': 0.00014782839571125805, 'start': 11},\n",
      " {'answer': 'Suvojit', 'end': 18, 'score': 0.00013227011368144304, 'start': 11},\n",
      " {'answer': 'Suvojit and',\n",
      "  'end': 22,\n",
      "  'score': 0.00010637977538863197,\n",
      "  'start': 11},\n",
      " {'answer': 'Senior Data Scientist',\n",
      "  'end': 51,\n",
      "  'score': 3.0426259399973787e-05,\n",
      "  'start': 30}]\n"
     ]
    }
   ],
   "source": [
    "API_URL = 'https://api-inference.huggingface.co/models/deepset/roberta-base-squad2'\n",
    "headers = {'Authorization': 'Bearer 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'}\n",
    "# headers = {'Authorization': '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'}\n",
    "\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "  \n",
    "params = {'max_length': 200, 'top_k': 10, 'temperature': 5.5}\n",
    "output = query({\n",
    "    'inputs': {\n",
    "            \"question\": \"What's my name?\",\n",
    "            \"context\": \"My name is Suvojit and I am a Senior Data Scientist\"\n",
    "        },\n",
    "    'parameters': params\n",
    "})\n",
    "\n",
    "pprint(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'A large language model, or LLM, is a deep learning model that can understand, learn, summarize, translate, predict, and generate text. Large language models are used in healthcare, software development, and use cases in many other fields. They aren’t just for teaching AIs human languages, but for understanding proteins, writing software code, and much more.'}]\n"
     ]
    }
   ],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "# headers = {'Authorization': 'Entertheaccesskeyhere'}\n",
    "headers = {'Authorization': 'Bearer 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'}\n",
    "\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "    \n",
    "params = {'do_sample': False}\n",
    "\n",
    "full_text = '''AI applications are summarizing articles, writing stories and \n",
    "engaging in long conversations — and large language models are doing \n",
    "the heavy lifting.\n",
    "\n",
    "A large language model, or LLM, is a deep learning model that can \n",
    "understand, learn, summarize, translate, predict, and generate text and other \n",
    "content based on knowledge gained from massive datasets.\n",
    "\n",
    "Large language models - successful applications of \n",
    "transformer models. They aren’t just for teaching AIs human languages, \n",
    "but for understanding proteins, writing software code, and much, much more.\n",
    "\n",
    "In addition to accelerating natural language processing applications — \n",
    "like translation, chatbots, and AI assistants — large language models are \n",
    "used in healthcare, software development, and use cases in many other fields.'''\n",
    "\n",
    "output = query({\n",
    "    'inputs': full_text,\n",
    "    'parameters': params\n",
    "})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/churnika/anaconda3/envs/my_project_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.22248071432113647, 'token': 2943, 'token_str': ' male', 'sequence': \"Hello, I'm a male model.\"}, {'score': 0.16759759187698364, 'token': 2734, 'token_str': ' fashion', 'sequence': \"Hello, I'm a fashion model.\"}, {'score': 0.05269981548190117, 'token': 2038, 'token_str': ' professional', 'sequence': \"Hello, I'm a professional model.\"}, {'score': 0.02748691849410534, 'token': 2182, 'token_str': ' female', 'sequence': \"Hello, I'm a female model.\"}, {'score': 0.026032207533717155, 'token': 18150, 'token_str': ' freelance', 'sequence': \"Hello, I'm a freelance model.\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='roberta-base')\n",
    "results = unmasker(\"Hello, I'm a <mask> model.\")\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
